# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/181su62iUw8UODFiFh2EIK04dug8KlMpR
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Streamlit UI
st.title("Music Genre Classification")
st.sidebar.header("Upload Dataset")

# Upload dataset
uploaded_tracks = st.sidebar.file_uploader("Upload fma-rock-vs-hiphop.csv", type=["csv"])
uploaded_echonest = st.sidebar.file_uploader("Upload echonest-metrics.json", type=["json"])

if uploaded_tracks and uploaded_echonest:
    tracks = pd.read_csv(uploaded_tracks)
    echonest_metrics = pd.read_json(uploaded_echonest, precise_float=True)

    # Merge datasets
    echo_tracks = pd.merge(echonest_metrics, tracks[["track_id", "genre_top"]], on='track_id')

    # Data Preprocessing
    X = echo_tracks.drop(columns=["track_id", "genre_top"])
    y = echo_tracks["genre_top"]

    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)

    scaler = StandardScaler()
    X = scaler.fit_transform(X)

    # Train-Test Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train models
    models = {
        "Decision Tree": DecisionTreeClassifier(max_depth=10, random_state=42),
        "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
        "SVM": SVC(kernel='rbf', C=1, probability=True),
        "Logistic Regression": LogisticRegression(C=1, max_iter=1000)
    }

    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        results[name] = accuracy_score(y_test, y_pred)

        # Display Confusion Matrix
        st.subheader(f"Confusion Matrix - {name}")
        fig, ax = plt.subplots()
        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', ax=ax)
        st.pyplot(fig)

    # Train Deep Learning Model
    model_dl = Sequential([
        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dropout(0.2),
        Dense(1, activation='sigmoid')
    ])

    model_dl.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    history = model_dl.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)

    # Accuracy plot
    st.subheader("Deep Learning Training Performance")
    fig, ax = plt.subplots()
    ax.plot(history.history['accuracy'], label='Train Accuracy')
    ax.plot(history.history['val_accuracy'], label='Val Accuracy')
    ax.legend()
    ax.set_title("Accuracy Curve")
    st.pyplot(fig)

    # Model comparison
    st.subheader("Model Comparison")
    best_model = max(results, key=results.get)
    st.write(f"Best Model: {best_model} with Accuracy {results[best_model]:.4f}")

