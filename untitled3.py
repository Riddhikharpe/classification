# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XWKm2545k-6VFsMbR4KAfkkcH2w-bAI3
"""

pip install tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import joblib
from flask import Flask, request, jsonify
import tensorflow as tf
from tensorflow import keras
from sklearn.feature_selection import SelectFromModel

# Step 1: Load Data
tracks = pd.read_csv('/content/sample_data/fma-rock-vs-hiphop.csv')
echonest_metrics = pd.read_json('/content/sample_data/echonest-metrics.json', precise_float=True)

# Merge datasets
echo_tracks = pd.merge(echonest_metrics, tracks[["track_id", "genre_top"]], on='track_id')

# Inspect dataset
print(echo_tracks.info())

# Data Preprocessing
X = echo_tracks.drop(columns=["track_id", "genre_top"])  # Features
y = echo_tracks["genre_top"]  # Target

# Encode Target Variable
from sklearn.preprocessing import LabelEncoder, StandardScaler
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Scale Features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.tree import DecisionTreeClassifier
import seaborn as sns
import matplotlib.pyplot as plt

# Train Decision Tree
dt = DecisionTreeClassifier(max_depth=10, random_state=42)
dt.fit(X_train, y_train)

# Predictions
y_pred_dt = dt.predict(X_test)

# Confusion Matrix Visualization
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Decision Tree")
plt.show()

from sklearn.ensemble import RandomForestClassifier

# Train Random Forest
rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
rf.fit(X_train, y_train)

# Predictions
y_pred_rf = rf.predict(X_test)

# Confusion Matrix Visualization
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Random Forest")
plt.show()

from sklearn.svm import SVC

# Train SVM
svm = SVC(kernel='rbf', C=1, probability=True)
svm.fit(X_train, y_train)

# Predictions
y_pred_svm = svm.predict(X_test)

# Confusion Matrix Visualization
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Oranges')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - SVM")
plt.show()

from sklearn.linear_model import LogisticRegression

# Train Logistic Regression
lr = LogisticRegression(C=1)
lr.fit(X_train, y_train)

# Predictions
y_pred_lr = lr.predict(X_test)

# Confusion Matrix Visualization
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='Purples')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

from sklearn.model_selection import GridSearchCV

# Hyperparameter Tuning for Random Forest
rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, None]}
grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy')
grid_rf.fit(X_train, y_train)
best_rf = grid_rf.best_estimator_

# Hyperparameter Tuning for SVM
svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
grid_svm = GridSearchCV(SVC(probability=True), svm_params, cv=5, scoring='accuracy')
grid_svm.fit(X_train, y_train)
best_svm = grid_svm.best_estimator_

# Hyperparameter Tuning for Logistic Regression
lr_params = {'C': [0.01, 0.1, 1, 10],'max_iter':[1000,2000,3000]}
grid_lr = GridSearchCV(LogisticRegression(), lr_params, cv=5, scoring='accuracy')
grid_lr.fit(X_train, y_train)
best_lr = grid_lr.best_estimator_

# Train models with best hyperparameters
best_rf.fit(X_train, y_train)
best_svm.fit(X_train, y_train)
best_lr.fit(X_train, y_train)

# Predictions
y_pred_rf = best_rf.predict(X_test)
y_pred_svm = best_svm.predict(X_test)
y_pred_lr = best_lr.predict(X_test)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Define Deep Learning Model
model_dl = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Compile and Train Model
model_dl.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model_dl.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

# Plot Training Loss & Accuracy
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.title("Loss Curve")

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Accuracy Curve")

plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

models = {'Random Forest': y_pred_rf, 'SVM': y_pred_svm, 'Logistic Regression': y_pred_lr, 'Deep Learning': y_pred_dl}

# Evaluate All Models
for name, y_pred in models.items():
    print(f"\nðŸ”¹ {name} Model Evaluation")
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"Precision: {precision_score(y_test, y_pred):.4f}")
    print(f"Recall: {recall_score(y_test, y_pred):.4f}")
    print(f"F1 Score: {f1_score(y_test, y_pred):.4f}")

    # Confusion Matrix Visualization
    plt.figure(figsize=(6,4))
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Confusion Matrix - {name}")
    plt.show()

from sklearn.metrics import roc_curve, roc_auc_score

# Compute ROC Curves
plt.figure(figsize=(8,6))
for model, name, y_pred_prob in zip([best_rf, best_svm, best_lr],
                                    ["Random Forest", "SVM", "Logistic Regression"],
                                    [best_rf.predict_proba(X_test)[:,1], best_svm.predict_proba(X_test)[:,1],
                                     best_lr.predict_proba(X_test)[:,1]]):

    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    plt.plot(fpr, tpr, label=f"{name} (AUC: {roc_auc_score(y_test, y_pred_prob):.2f})")

# Deep Learning ROC
fpr_dl, tpr_dl, _ = roc_curve(y_test, model_dl.predict(X_test).flatten())
plt.plot(fpr_dl, tpr_dl, label=f"Deep Learning (AUC: {roc_auc_score(y_test, model_dl.predict(X_test).flatten()):.2f})")

plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend()
plt.show()

# Compare Accuracy Scores
model_scores = {
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "SVM": accuracy_score(y_test, y_pred_svm),
    "Logistic Regression": accuracy_score(y_test, y_pred_lr),
    "Deep Learning": accuracy_score(y_test, y_pred_dl),
}

# Best Model
best_model_name = max(model_scores, key=model_scores.get)
print(f"âœ… Best Model: {best_model_name} with Accuracy {model_scores[best_model_name]:.4f}")

# Define the dictionary of trained models
best_model_dict = {
    "Random Forest": best_rf,
    "SVM": best_svm,
    "Logistic Regression": best_lr,
    "Deep Learning": model_dl
}

# Retrieve the best model
best_model_name = max(model_scores, key=model_scores.get)
best_model = best_model_dict[best_model_name]  # Assign the actual model, not a string

print(f"âœ… The Best Model is: {best_model_name} with Accuracy {model_scores[best_model_name]:.4f}")

import numpy as np
import matplotlib.pyplot as plt

# Check if the best model supports feature importance
if best_model_name == "Random Forest":
    # Get Feature Importances
    feature_importances = best_model.feature_importances_

    # Plot Feature Importances
    plt.figure(figsize=(10,5))
    plt.bar(np.arange(len(feature_importances)), feature_importances)
    plt.xlabel("Feature Index")
    plt.ylabel("Importance Score")
    plt.title(f"Feature Importance - {best_model_name}")
    plt.show()
else:
    print(f"âš  Feature importance is not available for {best_model_name}.")

